{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 12 - Processamento de Linguagem Natural</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Este é um material de bônus incluído neste curso. PyTorch é estudado em detalhes no curso <a href=\"https://www.datascienceacademy.com.br/course?courseid=deep-learning-frameworks\">Deep Learning Frameworks</a> e aplicado em PLN no curso <a href=\"https://www.datascienceacademy.com.br/course?courseid=processamento-de-linguagem-natural-e-reconhecimento-de-voz\">Processamento de Linguagem Natural</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudo de Caso - Inteligência Artificial Para Previsão de Sentenças em Embargos de Declaração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/embargos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A definição deste estudo de caso está no manual em pdf no Capítulo 12 do Curso de <a href=\"https://www.datascienceacademy.com.br/course?courseid=machine-learning-engineer\">Machine Learning</a>**. \n",
    "\n",
    "Faça a leitura do manual antes de prosseguir com o Estudo de Caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install torch==1.5.0\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o PyTorch\n",
    "!pip install -q torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.5.0\n",
      "numpy 1.18.2\n",
      "Data Science Academy\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os Dados\n",
    "\n",
    "O texto abaixo é um exemplo de embargo de declaração. Embora o texto represente um embargo, dados críticos foram substituídos por informações genéricas, o que não compromete o objetivo do estudo de caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de embargo de declaração\n",
    "embargo = \"\"\"O embargante sofreu o ajuizamento de ação de danos morais e materiais, cujo objeto é o reaver os \n",
    "valores pagos pelo sinal dado em um contrato de compra e venda de imóvel no qual não foi dado continuidade. Em 24 \n",
    "de fevereiro de 2012, o Magistrado proferiu decisão de fls. 277 a 280, que condenou todas as demandadas \n",
    "solidariamente no seguinte teor: Diante de todo o exposto, com fundamento no art. 1234, I, do CPC/2015, \n",
    "julgo procedentes em parte os pedidos constantes na inicial, condenando solidariamente as demandadas, XPTO LTDA, \n",
    "BOB CAMARGO DE MORAES, a Pagarema título de indenização por danos morais, consoante fundamentação acima discorrida, \n",
    "o montante de R$ 1.500,00 (um mil e quinhentos reais), corrigidos monetariamente pelo INPC desde a data \n",
    "desta decisão, acrescidos de juros de 1% ao mês, a partir da citação; condeno ainda, à restituição do valor \n",
    "pago pelo demandante como sinal da entrada do imóvel, descontando apenas 20% (vinte por cento), referente às \n",
    "despesas, devendo incidir juros de 1% (um por cento) ao mês contados da citação e correção monetária pelo INPC a \n",
    "partir da sentença. Contudo, data venia, houve omissão e obscuridade na referida decisão, haja vista que a omissão \n",
    "se deu pela ausência dos julgamentos das preliminares (Necessidade de Perícia Técnica e a incompetência de \n",
    "Juizado Especial) proposta posteriormente em aditamento de contestação (Fls 251 a 254) para impugnar áudios \n",
    "juntados pelo embargado, autorizado a ser realizada pela Douta Magistrada em audiência de Conciliação, \n",
    "instrução e julgamento de fls 235 e 236, por ausência de intimação anterior para realizar a já tratada \n",
    "impugnação aos áudios anexados.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza do texto substituindo vírgulas e pontos por espaços e colocando as palavras em minúsculo\n",
    "embargo = embargo.replace(',','').replace('.','').lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do corpus com o texto acima\n",
    "corpus = set(embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(fls',\n",
       " '(necessidade',\n",
       " '(um',\n",
       " '(vinte',\n",
       " '1%',\n",
       " '1234',\n",
       " '150000',\n",
       " '20%',\n",
       " '2012',\n",
       " '235',\n",
       " '236',\n",
       " '24',\n",
       " '251',\n",
       " '254)',\n",
       " '277',\n",
       " '280',\n",
       " 'a',\n",
       " 'acima',\n",
       " 'acrescidos',\n",
       " 'aditamento',\n",
       " 'ainda',\n",
       " 'ajuizamento',\n",
       " 'anexados',\n",
       " 'anterior',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'apenas',\n",
       " 'art',\n",
       " 'as',\n",
       " 'audiência',\n",
       " 'ausência',\n",
       " 'autorizado',\n",
       " 'ação',\n",
       " 'bob',\n",
       " 'camargo',\n",
       " 'cento)',\n",
       " 'citação',\n",
       " 'citação;',\n",
       " 'com',\n",
       " 'como',\n",
       " 'compra',\n",
       " 'conciliação',\n",
       " 'condenando',\n",
       " 'condeno',\n",
       " 'condenou',\n",
       " 'consoante',\n",
       " 'constantes',\n",
       " 'contados',\n",
       " 'contestação',\n",
       " 'continuidade',\n",
       " 'contrato',\n",
       " 'contudo',\n",
       " 'correção',\n",
       " 'corrigidos',\n",
       " 'cpc/2015',\n",
       " 'cujo',\n",
       " 'da',\n",
       " 'dado',\n",
       " 'danos',\n",
       " 'das',\n",
       " 'data',\n",
       " 'de',\n",
       " 'decisão',\n",
       " 'demandadas',\n",
       " 'demandante',\n",
       " 'descontando',\n",
       " 'desde',\n",
       " 'despesas',\n",
       " 'desta',\n",
       " 'deu',\n",
       " 'devendo',\n",
       " 'diante',\n",
       " 'discorrida',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'douta',\n",
       " 'e',\n",
       " 'em',\n",
       " 'embargado',\n",
       " 'embargante',\n",
       " 'entrada',\n",
       " 'especial)',\n",
       " 'exposto',\n",
       " 'fevereiro',\n",
       " 'fls',\n",
       " 'foi',\n",
       " 'fundamentação',\n",
       " 'fundamento',\n",
       " 'haja',\n",
       " 'houve',\n",
       " 'i',\n",
       " 'impugnar',\n",
       " 'impugnação',\n",
       " 'imóvel',\n",
       " 'incidir',\n",
       " 'incompetência',\n",
       " 'indenização',\n",
       " 'inicial',\n",
       " 'inpc',\n",
       " 'instrução',\n",
       " 'intimação',\n",
       " 'juizado',\n",
       " 'julgamento',\n",
       " 'julgamentos',\n",
       " 'julgo',\n",
       " 'juntados',\n",
       " 'juros',\n",
       " 'já',\n",
       " 'ltda',\n",
       " 'magistrada',\n",
       " 'magistrado',\n",
       " 'materiais',\n",
       " 'mil',\n",
       " 'monetariamente',\n",
       " 'monetária',\n",
       " 'montante',\n",
       " 'moraes',\n",
       " 'morais',\n",
       " 'mês',\n",
       " 'na',\n",
       " 'no',\n",
       " 'não',\n",
       " 'o',\n",
       " 'objeto',\n",
       " 'obscuridade',\n",
       " 'omissão',\n",
       " 'os',\n",
       " 'pagarema',\n",
       " 'pago',\n",
       " 'pagos',\n",
       " 'para',\n",
       " 'parte',\n",
       " 'partir',\n",
       " 'pedidos',\n",
       " 'pela',\n",
       " 'pelo',\n",
       " 'perícia',\n",
       " 'por',\n",
       " 'posteriormente',\n",
       " 'preliminares',\n",
       " 'procedentes',\n",
       " 'proferiu',\n",
       " 'proposta',\n",
       " 'qual',\n",
       " 'que',\n",
       " 'quinhentos',\n",
       " 'r$',\n",
       " 'reais)',\n",
       " 'realizada',\n",
       " 'realizar',\n",
       " 'reaver',\n",
       " 'referente',\n",
       " 'referida',\n",
       " 'restituição',\n",
       " 'se',\n",
       " 'seguinte',\n",
       " 'sentença',\n",
       " 'ser',\n",
       " 'sinal',\n",
       " 'sofreu',\n",
       " 'solidariamente',\n",
       " 'teor:',\n",
       " 'todas',\n",
       " 'todo',\n",
       " 'tratada',\n",
       " 'técnica',\n",
       " 'título',\n",
       " 'um',\n",
       " 'valor',\n",
       " 'valores',\n",
       " 'venda',\n",
       " 'venia',\n",
       " 'vista',\n",
       " 'xpto',\n",
       " 'à',\n",
       " 'às',\n",
       " 'áudios',\n",
       " 'é'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos o corpus\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimento do corpus\n",
    "corpus_length = len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionários para TF-IDF\n",
    "dic_palavra = {}\n",
    "dic_inverso_palavra = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop pelo corpus para criar os dicionários\n",
    "for i, palavra in enumerate(corpus):\n",
    "    dic_palavra[palavra] = i\n",
    "    dic_inverso_palavra[i] = palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para receber os dados\n",
    "dados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop pelo texto par extrair sentenças e palavras\n",
    "for i in range(2, len(embargo) - 2):\n",
    "    sentence = [embargo[i-2], embargo[i-1], embargo[i+1], embargo[i+2]]\n",
    "    target = embargo[i]\n",
    "    dados.append((sentence, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você leu o código acima e compreendeu o que foi feito? Observe esta linha:\n",
    "\n",
    "sentence = [embargo[i-2], embargo[i-1], embargo[i+1], embargo[i+2]]\n",
    "\n",
    "Para uma palavra no índice i, obtemos duas palavras antes e duas palavras depois. A palavra no índice i será o nosso target e a sentença será composta das duas palavras e duas palavras depois da palavra target. \n",
    "\n",
    "Após treinar o modelo, seremos capazes de prever cada palavra com base nas palavras a sua volta.\n",
    "\n",
    "Aqui um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['o', 'ajuizamento', 'ação', 'de'], 'de')\n"
     ]
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "print(dados[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As quatro palavras na lista serão os dados de entrada e a palavra fora da lista ('de' nesse caso), será a variável de saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção do Modelo CBoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos definir o comprimento de cada embedding\n",
    "embedding_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para o modelo\n",
    "class CBoW(torch.nn.Module):\n",
    "\n",
    "    # Método construtor\n",
    "    def __init__(self, corpus_length, embedding_dim):\n",
    "        super(CBoW, self).__init__()\n",
    "        \n",
    "        # Camada de entrada do modelo para criação da embedding\n",
    "        self.embeddings = nn.Embedding(corpus_length, embedding_dim)\n",
    "\n",
    "        # Camadas lineares\n",
    "        self.linear1 = nn.Linear(embedding_dim, 64)\n",
    "        self.linear2 = nn.Linear(64, corpus_length)\n",
    "        \n",
    "        # Camadas de ativação\n",
    "        self.activation_function1 = nn.ReLU()\n",
    "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
    "\n",
    "    # Passo (forward)\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # Aqui definimos a ordem ds camadas da rede neural\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out\n",
    "\n",
    "    # Obtém a word_emdedding\n",
    "    def get_word_emdedding(self, word):\n",
    "        word = torch.LongTensor([dic_palavra[word]])\n",
    "        return self.embeddings(word).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo CBoW\n",
    "modelo = CBoW(corpus_length, embedding_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de custo\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador do modelo (backpropagation)\n",
    "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o vetor de sentenças, necessário para treinar o modelo\n",
    "def make_sentence_vector(sentence, word_dict):\n",
    "    idxs = [word_dict[w] for w in sentence]\n",
    "    return torch.tensor(idxs, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20%': 0,\n",
       " 'para': 1,\n",
       " 'realizar': 2,\n",
       " 'acrescidos': 3,\n",
       " 'incompetência': 4,\n",
       " 'julgamentos': 5,\n",
       " 'juizado': 6,\n",
       " 'perícia': 7,\n",
       " '251': 8,\n",
       " 'montante': 9,\n",
       " 'obscuridade': 10,\n",
       " 'omissão': 11,\n",
       " 'venda': 12,\n",
       " '236': 13,\n",
       " 'corrigidos': 14,\n",
       " 'na': 15,\n",
       " 'embargado': 16,\n",
       " 'pagarema': 17,\n",
       " 'posteriormente': 18,\n",
       " 'sinal': 19,\n",
       " 'um': 20,\n",
       " 'aos': 21,\n",
       " 'preliminares': 22,\n",
       " '(um': 23,\n",
       " 'pago': 24,\n",
       " 'dos': 25,\n",
       " 'houve': 26,\n",
       " '1%': 27,\n",
       " 'quinhentos': 28,\n",
       " 'demandadas': 29,\n",
       " 'mês': 30,\n",
       " 'condenou': 31,\n",
       " 'discorrida': 32,\n",
       " 'pela': 33,\n",
       " 'como': 34,\n",
       " 'valores': 35,\n",
       " 'no': 36,\n",
       " '2012': 37,\n",
       " 'partir': 38,\n",
       " '280': 39,\n",
       " 'impugnação': 40,\n",
       " 'inpc': 41,\n",
       " 'correção': 42,\n",
       " 'áudios': 43,\n",
       " 'desde': 44,\n",
       " 'restituição': 45,\n",
       " 'às': 46,\n",
       " 'ajuizamento': 47,\n",
       " 'reais)': 48,\n",
       " 'solidariamente': 49,\n",
       " 'data': 50,\n",
       " 'tratada': 51,\n",
       " 'haja': 52,\n",
       " 'apenas': 53,\n",
       " 'impugnar': 54,\n",
       " 'diante': 55,\n",
       " '(vinte': 56,\n",
       " 'julgamento': 57,\n",
       " 'compra': 58,\n",
       " 'seguinte': 59,\n",
       " 'cento)': 60,\n",
       " 'demandante': 61,\n",
       " 'descontando': 62,\n",
       " 'contados': 63,\n",
       " 'se': 64,\n",
       " '254)': 65,\n",
       " '(fls': 66,\n",
       " 'autorizado': 67,\n",
       " 'contudo': 68,\n",
       " 'técnica': 69,\n",
       " 'referida': 70,\n",
       " 'sofreu': 71,\n",
       " 'art': 72,\n",
       " 'que': 73,\n",
       " 'em': 74,\n",
       " 'a': 75,\n",
       " 'decisão': 76,\n",
       " 'citação;': 77,\n",
       " 'objeto': 78,\n",
       " '277': 79,\n",
       " 'anexados': 80,\n",
       " 'já': 81,\n",
       " 'à': 82,\n",
       " 'proferiu': 83,\n",
       " 'inicial': 84,\n",
       " 'fundamento': 85,\n",
       " 'valor': 86,\n",
       " 'pagos': 87,\n",
       " '24': 88,\n",
       " 'contrato': 89,\n",
       " 'camargo': 90,\n",
       " 'título': 91,\n",
       " 'ltda': 92,\n",
       " 'cujo': 93,\n",
       " 'de': 94,\n",
       " 'não': 95,\n",
       " 'monetariamente': 96,\n",
       " 'dado': 97,\n",
       " 'foi': 98,\n",
       " 'exposto': 99,\n",
       " 'douta': 100,\n",
       " 'os': 101,\n",
       " 'ausência': 102,\n",
       " 'magistrada': 103,\n",
       " 'audiência': 104,\n",
       " 'entrada': 105,\n",
       " 'devendo': 106,\n",
       " 'venia': 107,\n",
       " 'intimação': 108,\n",
       " 'sentença': 109,\n",
       " 'pedidos': 110,\n",
       " 'com': 111,\n",
       " '1234': 112,\n",
       " '150000': 113,\n",
       " 'danos': 114,\n",
       " 'o': 115,\n",
       " 'r$': 116,\n",
       " '235': 117,\n",
       " 'teor:': 118,\n",
       " 'parte': 119,\n",
       " 'constantes': 120,\n",
       " 'qual': 121,\n",
       " 'é': 122,\n",
       " 'ainda': 123,\n",
       " 'da': 124,\n",
       " 'todas': 125,\n",
       " 'reaver': 126,\n",
       " 'pelo': 127,\n",
       " 'condenando': 128,\n",
       " 'consoante': 129,\n",
       " 'as': 130,\n",
       " 'i': 131,\n",
       " 'moraes': 132,\n",
       " 'desta': 133,\n",
       " 'especial)': 134,\n",
       " 'ser': 135,\n",
       " 'das': 136,\n",
       " 'todo': 137,\n",
       " 'embargante': 138,\n",
       " 'do': 139,\n",
       " '(necessidade': 140,\n",
       " 'incidir': 141,\n",
       " 'juros': 142,\n",
       " 'juntados': 143,\n",
       " 'despesas': 144,\n",
       " 'referente': 145,\n",
       " 'fevereiro': 146,\n",
       " 'morais': 147,\n",
       " 'fls': 148,\n",
       " 'magistrado': 149,\n",
       " 'contestação': 150,\n",
       " 'conciliação': 151,\n",
       " 'vista': 152,\n",
       " 'bob': 153,\n",
       " 'julgo': 154,\n",
       " 'proposta': 155,\n",
       " 'ação': 156,\n",
       " 'cpc/2015': 157,\n",
       " 'xpto': 158,\n",
       " 'citação': 159,\n",
       " 'anterior': 160,\n",
       " 'por': 161,\n",
       " 'materiais': 162,\n",
       " 'monetária': 163,\n",
       " 'procedentes': 164,\n",
       " 'aditamento': 165,\n",
       " 'continuidade': 166,\n",
       " 'e': 167,\n",
       " 'fundamentação': 168,\n",
       " 'mil': 169,\n",
       " 'realizada': 170,\n",
       " 'indenização': 171,\n",
       " 'deu': 172,\n",
       " 'instrução': 173,\n",
       " 'imóvel': 174,\n",
       " 'acima': 175,\n",
       " 'ao': 176,\n",
       " 'condeno': 177}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui está nosso dicionário de palavras\n",
    "dic_palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 33, 102,  25,   5])\n"
     ]
    }
   ],
   "source": [
    "# O dicionário de palavras será convertido em um vetor de sentenças. Aqui um exemplo:\n",
    "print(make_sentence_vector(['pela','ausência','dos','julgamentos'], dic_palavra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Erro do Modelo: 1349.9468994140625\n",
      "Epoch: 1, Erro do Modelo: 1222.0167236328125\n",
      "Epoch: 2, Erro do Modelo: 1123.184814453125\n",
      "Epoch: 3, Erro do Modelo: 1026.185546875\n",
      "Epoch: 4, Erro do Modelo: 923.4420166015625\n",
      "Epoch: 5, Erro do Modelo: 814.168701171875\n",
      "Epoch: 6, Erro do Modelo: 699.1925048828125\n",
      "Epoch: 7, Erro do Modelo: 583.171142578125\n",
      "Epoch: 8, Erro do Modelo: 470.5594177246094\n",
      "Epoch: 9, Erro do Modelo: 366.5306091308594\n",
      "Epoch: 10, Erro do Modelo: 276.91217041015625\n",
      "Epoch: 11, Erro do Modelo: 204.39186096191406\n",
      "Epoch: 12, Erro do Modelo: 150.15167236328125\n",
      "Epoch: 13, Erro do Modelo: 110.65082550048828\n",
      "Epoch: 14, Erro do Modelo: 84.32002258300781\n",
      "Epoch: 15, Erro do Modelo: 65.56706237792969\n",
      "Epoch: 16, Erro do Modelo: 52.40394973754883\n",
      "Epoch: 17, Erro do Modelo: 43.125732421875\n",
      "Epoch: 18, Erro do Modelo: 35.943904876708984\n",
      "Epoch: 19, Erro do Modelo: 30.393281936645508\n",
      "Epoch: 20, Erro do Modelo: 25.812850952148438\n",
      "Epoch: 21, Erro do Modelo: 21.962703704833984\n",
      "Epoch: 22, Erro do Modelo: 19.411964416503906\n",
      "Epoch: 23, Erro do Modelo: 17.448938369750977\n",
      "Epoch: 24, Erro do Modelo: 15.847818374633789\n",
      "Epoch: 25, Erro do Modelo: 14.512517929077148\n",
      "Epoch: 26, Erro do Modelo: 13.382279396057129\n",
      "Epoch: 27, Erro do Modelo: 12.404853820800781\n",
      "Epoch: 28, Erro do Modelo: 11.558392524719238\n",
      "Epoch: 29, Erro do Modelo: 10.815959930419922\n",
      "Epoch: 30, Erro do Modelo: 10.159317970275879\n",
      "Epoch: 31, Erro do Modelo: 9.572794914245605\n",
      "Epoch: 32, Erro do Modelo: 9.05075454711914\n",
      "Epoch: 33, Erro do Modelo: 8.57990837097168\n",
      "Epoch: 34, Erro do Modelo: 8.154056549072266\n",
      "Epoch: 35, Erro do Modelo: 7.765678405761719\n",
      "Epoch: 36, Erro do Modelo: 7.412943363189697\n",
      "Epoch: 37, Erro do Modelo: 7.0879387855529785\n",
      "Epoch: 38, Erro do Modelo: 6.788045883178711\n",
      "Epoch: 39, Erro do Modelo: 6.515204906463623\n",
      "Epoch: 40, Erro do Modelo: 6.258686542510986\n",
      "Epoch: 41, Erro do Modelo: 6.022176742553711\n",
      "Epoch: 42, Erro do Modelo: 5.8013482093811035\n",
      "Epoch: 43, Erro do Modelo: 5.5964155197143555\n",
      "Epoch: 44, Erro do Modelo: 5.404721260070801\n",
      "Epoch: 45, Erro do Modelo: 5.225059986114502\n",
      "Epoch: 46, Erro do Modelo: 5.055937767028809\n",
      "Epoch: 47, Erro do Modelo: 4.8967461585998535\n",
      "Epoch: 48, Erro do Modelo: 4.7479095458984375\n",
      "Epoch: 49, Erro do Modelo: 4.606714248657227\n",
      "Epoch: 50, Erro do Modelo: 4.4730401039123535\n",
      "Epoch: 51, Erro do Modelo: 4.346855163574219\n",
      "Epoch: 52, Erro do Modelo: 4.226576805114746\n",
      "Epoch: 53, Erro do Modelo: 4.113689422607422\n",
      "Epoch: 54, Erro do Modelo: 4.005241394042969\n",
      "Epoch: 55, Erro do Modelo: 3.9025278091430664\n",
      "Epoch: 56, Erro do Modelo: 3.8043932914733887\n",
      "Epoch: 57, Erro do Modelo: 3.711374521255493\n",
      "Epoch: 58, Erro do Modelo: 3.6219189167022705\n",
      "Epoch: 59, Erro do Modelo: 3.53671932220459\n",
      "Epoch: 60, Erro do Modelo: 3.4552955627441406\n",
      "Epoch: 61, Erro do Modelo: 3.3775134086608887\n",
      "Epoch: 62, Erro do Modelo: 3.30267333984375\n",
      "Epoch: 63, Erro do Modelo: 3.231041431427002\n",
      "Epoch: 64, Erro do Modelo: 3.1622626781463623\n",
      "Epoch: 65, Erro do Modelo: 3.0961766242980957\n",
      "Epoch: 66, Erro do Modelo: 3.032454013824463\n",
      "Epoch: 67, Erro do Modelo: 2.971459150314331\n",
      "Epoch: 68, Erro do Modelo: 2.9127118587493896\n",
      "Epoch: 69, Erro do Modelo: 2.855962038040161\n",
      "Epoch: 70, Erro do Modelo: 2.8015356063842773\n",
      "Epoch: 71, Erro do Modelo: 2.748586893081665\n",
      "Epoch: 72, Erro do Modelo: 2.6980502605438232\n",
      "Epoch: 73, Erro do Modelo: 2.648928165435791\n",
      "Epoch: 74, Erro do Modelo: 2.6012721061706543\n",
      "Epoch: 75, Erro do Modelo: 2.5557074546813965\n",
      "Epoch: 76, Erro do Modelo: 2.511359930038452\n",
      "Epoch: 77, Erro do Modelo: 2.468411445617676\n",
      "Epoch: 78, Erro do Modelo: 2.4266343116760254\n",
      "Epoch: 79, Erro do Modelo: 2.3867220878601074\n",
      "Epoch: 80, Erro do Modelo: 2.347399950027466\n",
      "Epoch: 81, Erro do Modelo: 2.3097379207611084\n",
      "Epoch: 82, Erro do Modelo: 2.2731266021728516\n",
      "Epoch: 83, Erro do Modelo: 2.2374043464660645\n",
      "Epoch: 84, Erro do Modelo: 2.2029671669006348\n",
      "Epoch: 85, Erro do Modelo: 2.16933274269104\n",
      "Epoch: 86, Erro do Modelo: 2.1366820335388184\n",
      "Epoch: 87, Erro do Modelo: 2.1049349308013916\n",
      "Epoch: 88, Erro do Modelo: 2.0741028785705566\n",
      "Epoch: 89, Erro do Modelo: 2.0441596508026123\n",
      "Epoch: 90, Erro do Modelo: 2.0150201320648193\n",
      "Epoch: 91, Erro do Modelo: 1.986457109451294\n",
      "Epoch: 92, Erro do Modelo: 1.9588990211486816\n",
      "Epoch: 93, Erro do Modelo: 1.9319071769714355\n",
      "Epoch: 94, Erro do Modelo: 1.9055379629135132\n",
      "Epoch: 95, Erro do Modelo: 1.8800699710845947\n",
      "Epoch: 96, Erro do Modelo: 1.8551141023635864\n",
      "Epoch: 97, Erro do Modelo: 1.8307725191116333\n",
      "Epoch: 98, Erro do Modelo: 1.8070284128189087\n",
      "Epoch: 99, Erro do Modelo: 1.783876895904541\n",
      "Epoch: 100, Erro do Modelo: 1.761231780052185\n",
      "Epoch: 101, Erro do Modelo: 1.739220380783081\n",
      "Epoch: 102, Erro do Modelo: 1.7176412343978882\n",
      "Epoch: 103, Erro do Modelo: 1.6965293884277344\n",
      "Epoch: 104, Erro do Modelo: 1.6760222911834717\n",
      "Epoch: 105, Erro do Modelo: 1.655885100364685\n",
      "Epoch: 106, Erro do Modelo: 1.636263370513916\n",
      "Epoch: 107, Erro do Modelo: 1.616947054862976\n",
      "Epoch: 108, Erro do Modelo: 1.598206877708435\n",
      "Epoch: 109, Erro do Modelo: 1.579779863357544\n",
      "Epoch: 110, Erro do Modelo: 1.5617890357971191\n",
      "Epoch: 111, Erro do Modelo: 1.5441462993621826\n",
      "Epoch: 112, Erro do Modelo: 1.52695631980896\n",
      "Epoch: 113, Erro do Modelo: 1.509978175163269\n",
      "Epoch: 114, Erro do Modelo: 1.4935064315795898\n",
      "Epoch: 115, Erro do Modelo: 1.4772604703903198\n",
      "Epoch: 116, Erro do Modelo: 1.4613264799118042\n",
      "Epoch: 117, Erro do Modelo: 1.4458967447280884\n",
      "Epoch: 118, Erro do Modelo: 1.430543303489685\n",
      "Epoch: 119, Erro do Modelo: 1.4156523942947388\n",
      "Epoch: 120, Erro do Modelo: 1.400955319404602\n",
      "Epoch: 121, Erro do Modelo: 1.3866212368011475\n",
      "Epoch: 122, Erro do Modelo: 1.3725043535232544\n",
      "Epoch: 123, Erro do Modelo: 1.3585929870605469\n",
      "Epoch: 124, Erro do Modelo: 1.3451491594314575\n",
      "Epoch: 125, Erro do Modelo: 1.331799864768982\n",
      "Epoch: 126, Erro do Modelo: 1.318688154220581\n",
      "Epoch: 127, Erro do Modelo: 1.305888056755066\n",
      "Epoch: 128, Erro do Modelo: 1.2932881116867065\n",
      "Epoch: 129, Erro do Modelo: 1.2808709144592285\n",
      "Epoch: 130, Erro do Modelo: 1.268802285194397\n",
      "Epoch: 131, Erro do Modelo: 1.2568093538284302\n",
      "Epoch: 132, Erro do Modelo: 1.2450624704360962\n",
      "Epoch: 133, Erro do Modelo: 1.2335960865020752\n",
      "Epoch: 134, Erro do Modelo: 1.2222487926483154\n",
      "Epoch: 135, Erro do Modelo: 1.2111310958862305\n",
      "Epoch: 136, Erro do Modelo: 1.200166940689087\n",
      "Epoch: 137, Erro do Modelo: 1.1894017457962036\n",
      "Epoch: 138, Erro do Modelo: 1.1789168119430542\n",
      "Epoch: 139, Erro do Modelo: 1.168442726135254\n",
      "Epoch: 140, Erro do Modelo: 1.1582189798355103\n",
      "Epoch: 141, Erro do Modelo: 1.1482043266296387\n",
      "Epoch: 142, Erro do Modelo: 1.1382590532302856\n",
      "Epoch: 143, Erro do Modelo: 1.1285512447357178\n",
      "Epoch: 144, Erro do Modelo: 1.1189442873001099\n",
      "Epoch: 145, Erro do Modelo: 1.1095116138458252\n",
      "Epoch: 146, Erro do Modelo: 1.100261926651001\n",
      "Epoch: 147, Erro do Modelo: 1.091101884841919\n",
      "Epoch: 148, Erro do Modelo: 1.0820868015289307\n",
      "Epoch: 149, Erro do Modelo: 1.073244571685791\n"
     ]
    }
   ],
   "source": [
    "# Loop por 150 passadas (epochs) de treinamento\n",
    "for epoch in range(150):\n",
    "    \n",
    "    # Inicia o erro da época com 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Loop pelos dados de entrada (sentence) e saída (target)\n",
    "    for sentence, target in dados:\n",
    "        \n",
    "        # Inicializa os gradientes com zero\n",
    "        modelo.zero_grad()\n",
    "        \n",
    "        # Cria o vetor de sentença com os dados de entrada (que devem estar no dicionário de palavras)\n",
    "        sentence_vector = make_sentence_vector(sentence, dic_palavra)  \n",
    "        \n",
    "        # Usa o vetor para fazer previsões com o modelo e retorna as probabilidades\n",
    "        log_probs = modelo(sentence_vector)\n",
    "        \n",
    "        # Calcula o erro do modelo\n",
    "        loss = loss_function(log_probs, torch.tensor([dic_palavra[target]], dtype = torch.long))\n",
    "        \n",
    "        # Chama o método de backpropagation para calcular o gradiente da derivada\n",
    "        loss.backward()\n",
    "        \n",
    "        # Otimiza os pesos do modelo e segue para a próxima passada\n",
    "        # É aqui que o aprendizado acontece\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Atualiza o erro da época\n",
    "        epoch_loss += loss.data\n",
    "        \n",
    "    # Imprime epoch e erro da epoch    \n",
    "    print('Epoch: ' + str(epoch) + ', Erro do Modelo: ' + str(epoch_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como o erro foi reduzido a cada passada, nitidamente o aprendizado ocorrendo. Vamos agora usar o modelo para fazer previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter uma previsão\n",
    "def get_resultado_previsto(input, dic_inverso_palavra):\n",
    "    index = np.argmax(input)\n",
    "    return dic_inverso_palavra[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para prever sentenças (aplicamos aos novos dados o mesmo tratamento usado nos dados de treino)\n",
    "def preve_sentenca(sentence):\n",
    "    \n",
    "    # Dividimos a sentença com split\n",
    "    sentence_split = sentence.replace('.','').lower().split()\n",
    "    \n",
    "    # Criamos o vetor de sentença\n",
    "    sentence_vector = make_sentence_vector(sentence_split, dic_palavra)\n",
    "    \n",
    "    # Faz a previsão com o modelo\n",
    "    prediction_array = modelo(sentence_vector).data.numpy()\n",
    "    \n",
    "    # Print dos resultados\n",
    "    print('Palavras Anteriores: {}\\n'.format(sentence_split[:2]))\n",
    "    print('Palavra Prevista: {}\\n'.format(get_resultado_previsto(prediction_array[0], dic_inverso_palavra)))\n",
    "    print('Palavras Seguintes: {}\\n'.format(sentence_split[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões com o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro da frase: **\"ausência de intimação anterior para realizar\"**, vejamos se o modelo consegue prever a palavra.\n",
    "\n",
    "Vou omitir a palavra **intimação** e essa deve ser a palavra prevista pelo modelo. Vamos passar como dados de entrada as duas palavras anteriores e as duas palavras posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras Anteriores: ['ausência', 'de']\n",
      "\n",
      "Palavra Prevista: intimação\n",
      "\n",
      "Palavras Seguintes: ['anterior', 'para']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Previsão com o modelo\n",
    "preve_sentenca('ausência de anterior para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9246,  0.2517, -0.6917,  0.1016, -0.5898, -0.6693,  0.6703,  1.3784,\n",
      "          1.2231, -0.8615, -0.5857,  0.3420, -0.7337, -1.0864,  0.9474,  0.7901,\n",
      "          0.4599,  0.5518, -1.0639,  1.0161]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Emdedding da palavra\n",
    "print(modelo.get_word_emdedding('intimação'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito! O modelo fez a previsão da sentença no Embargo de Declaração! Mais um exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro da frase: **\"devendo incidir juros de 1%\"**, vejamos se o modelo consegue prever a palavra.\n",
    "\n",
    "Vou omitir a palavra **juros** e essa deve ser a palavra prevista pelo modelo. Vamos passar como dados de entrada as duas palavras anteriores e as duas palavras posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras Anteriores: ['devendo', 'incidir']\n",
      "\n",
      "Palavra Prevista: juros\n",
      "\n",
      "Palavras Seguintes: ['de', '1%']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Previsão com o modelo\n",
    "preve_sentenca('devendo incidir de 1%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito! O modelo fez a previsão da sentença no Embargo de Declaração! E o CBoW não é o modelo mais avançado em PLN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
